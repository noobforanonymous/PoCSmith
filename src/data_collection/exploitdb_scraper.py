#!/usr/bin/env python3
"""
Exploit-DB Scraper for ExploitGPT
Clones Exploit-DB repository and extracts exploit code and metadata
"""

import os
import csv
import json
import shutil
import subprocess
import argparse
from pathlib import Path
from typing import Dict, List, Optional
from datetime import datetime

class ExploitDBScraper:
    """Scraper for Exploit-DB data"""
    
    REPO_URL = "https://gitlab.com/exploit-database/exploitdb.git"
    
    def __init__(self, output_dir: str = "data/raw/exploits/exploitdb"):
        self.output_dir = Path(output_dir)
        self.repo_dir = self.output_dir / "repo"
        self.data_dir = self.output_dir / "json"
        
        self.output_dir.mkdir(parents=True, exist_ok=True)
        self.data_dir.mkdir(parents=True, exist_ok=True)
        
        self.stats = {
            "total_processed": 0,
            "total_saved": 0,
            "errors": 0
        }

    def sync_repo(self):
        """Clone or pull the Exploit-DB repository"""
        if self.repo_dir.exists():
            print("[UPDATE] Updating Exploit-DB repository...")
            try:
                subprocess.run(["git", "-C", str(self.repo_dir), "pull"], check=True)
                print("[OK] Repository updated")
            except subprocess.CalledProcessError as e:
                print(f"[ERROR] Error updating repo: {e}")
        else:
            print("[CLONE] Cloning Exploit-DB repository...")
            try:
                subprocess.run(["git", "clone", self.REPO_URL, str(self.repo_dir)], check=True)
                print("[OK] Repository cloned")
            except subprocess.CalledProcessError as e:
                print(f"[ERROR] Error cloning repo: {e}")
                raise

    def parse_exploits(self, limit: Optional[int] = None, platform: Optional[str] = None) -> List[Dict]:
        """
        Parse exploits from the repository
        
        Args:
            limit: Maximum number of exploits to process
            platform: Filter by platform (e.g., 'windows', 'linux')
            
        Returns:
            List of exploit dictionaries
        """
        csv_path = self.repo_dir / "files_exploits.csv"
        if not csv_path.exists():
            raise FileNotFoundError(f"files_exploits.csv not found in {self.repo_dir}")
            
        exploits = []
        
        print("[PARSE] Parsing exploits...")
        
        try:
            with open(csv_path, 'r', encoding='utf-8') as f:
                reader = csv.DictReader(f)
                
                for row in reader:
                    # Apply filters
                    if platform and platform.lower() not in row.get('platform', '').lower():
                        continue
                        
                    try:
                        exploit_data = self._process_exploit(row)
                        if exploit_data:
                            exploits.append(exploit_data)
                            self.stats["total_processed"] += 1
                            
                            if limit and self.stats["total_processed"] >= limit:
                                break
                                
                    except Exception as e:
                        # print(f"   [WARNING] Error processing exploit {row.get('id')}: {e}")
                        self.stats["errors"] += 1
                        
        except Exception as e:
            print(f"[ERROR] Error reading CSV: {e}")
            raise
            
        print(f"[OK] Processed {len(exploits)} exploits")
        return exploits

    def _process_exploit(self, row: Dict) -> Optional[Dict]:
        """Process a single exploit row"""
        exploit_id = row.get('id')
        file_path = row.get('file')
        description = row.get('description')
        date = row.get('date')
        author = row.get('author')
        platform = row.get('platform')
        exploit_type = row.get('type')
        port = row.get('port')
        codes = row.get('codes')
        
        full_path = self.repo_dir / file_path
        
        if not full_path.exists():
            return None
            
        # Read content
        try:
            # Try UTF-8 first
            with open(full_path, 'r', encoding='utf-8') as f:
                content = f.read()
        except UnicodeDecodeError:
            try:
                # Try latin-1 for binary/older files
                with open(full_path, 'r', encoding='latin-1') as f:
                    content = f.read()
            except Exception:
                return None
                
        return {
            "id": exploit_id,
            "description": description,
            "date": date,
            "author": author,
            "platform": platform,
            "type": exploit_type,
            "port": port,
            "codes": codes,
            "extension": full_path.suffix,
            "content": content
        }

    def save_exploits(self, exploits: List[Dict], filename: Optional[str] = None):
        """Save exploits to JSON file"""
        if not exploits:
            print("[WARNING] No exploits to save")
            return
            
        if not filename:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"exploitdb_{timestamp}.json"
            
        output_path = self.data_dir / filename
        
        try:
            with open(output_path, 'w', encoding='utf-8') as f:
                json.dump(exploits, f, indent=2, ensure_ascii=False)
                
            self.stats["total_saved"] = len(exploits)
            print(f"[OK] Saved {len(exploits)} exploits to {output_path}")
            
        except Exception as e:
            print(f"[ERROR] Error saving exploits: {e}")
            self.stats["errors"] += 1

    def print_stats(self):
        """Print statistics"""
        print("\n" + "="*60)
        print("[STATS] Exploit-DB Scraper Statistics")
        print("="*60)
        print(f"Total processed: {self.stats['total_processed']}")
        print(f"Total saved:     {self.stats['total_saved']}")
        print(f"Errors:          {self.stats['errors']}")
        print("="*60)

def main():
    parser = argparse.ArgumentParser(description="Scrape Exploit-DB data")
    parser.add_argument("--limit", type=int, help="Limit number of exploits")
    parser.add_argument("--platform", help="Filter by platform")
    parser.add_argument("--output", help="Output filename")
    parser.add_argument("--output-dir", default="data/raw/exploits/exploitdb", help="Output directory")
    parser.add_argument("--skip-sync", action="store_true", help="Skip repo sync")
    
    args = parser.parse_args()
    
    print("="*60)
    print("[EXPLOITDB] ExploitGPT Exploit-DB Scraper")
    print("="*60)
    
    scraper = ExploitDBScraper(output_dir=args.output_dir)
    
    if not args.skip_sync:
        scraper.sync_repo()
        
    exploits = scraper.parse_exploits(limit=args.limit, platform=args.platform)
    
    if exploits:
        scraper.save_exploits(exploits, filename=args.output)
        
    scraper.print_stats()

if __name__ == "__main__":
    main()
